y
y=2:20
x = 1:19
glm(y ~ x)
glm(price ~ store + subject, data=groceries2)
anova(price ~ store + subject, data=groceries2)
aov(price ~ store + subject, data=groceries2)
summary(aov(price ~ store + subject, data=groceries2))
summary(glm(price ~ store + subject, data=groceries2))
summary(lm(price ~ store + subject, data=groceries2))
glm(price ~ store + subject, data=groceries2, test='F')
?glm
?glm
anova(glm(price ~ store + subject, data=groceries2))
summary(lm(price ~ store + subject, data=groceries2))
anova(glm(price ~ store + subject, data=groceries2))
summary(glm(price ~ store + subject, data=groceries2))
summary(lm(price ~ store + subject, data=groceries2))
?anova.glm
glm.1 <- glm(price ~ store + subject, data=groceries2)
glm.0 <- glm(price ~ 1)
glm.0 <- glm(price ~ 1, data=groceries2)
anova(glm.1, glm.0, test="F")
install.packages("lme4", dependencies = T)
library(lme4)
?lmer
data(sleepstudy)
View(sleepstudy)
fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
summary(fm1)
sqrt(612.09)
fm1
summary(fm1)
coef(fm1)
plot(price )
attach(groceries2)
plot(price)
names(groceries2)
plot(price, color=store)
plot(price, col=store)
?lmer
demo2 <- read.csv("http://www.ats.ucla.edu/stat/data/demo2.csv")
## Convert variables to factor
demo2 <- within(demo2, {
group <- factor(group)
time <- factor(time)
id <- factor(id)
})
View(demo2)
View(demo2)
par(cex = .6)
with(demo2, interaction.plot(time, group, pulse,
ylim = c(10, 40), lty = c(1, 12), lwd = 3,
ylab = "mean of pulse", xlab = "time", trace.label = "group"))
demo2.aov <- aov(pulse ~ group * time + Error(id), data = demo2)
summary(demo2.aov)
0.5446756/(0.092316/16.95)
0.047147/(0.027917/16.89)
100000000/1e6
is.na(NA)
is.na(infty)
View(dat)
View(dat)
attach(dat)
lm(y ~ x1 + x2 + x3)
summary(dat)
class(x1)
class(x2)
class(x3)
class(y)
lm(y ~ x1 + x2 )
lm(y ~ x1 + x2, drop.unused.levels=T )
dim(y)
attach(dat)
dim(y)
lm(dat$y ~ dat$x1 + dat$x2, drop.unused.levels=T )
lm(dat$y ~ dat$x1 + dat$x2)
dat$y[100:110] = NA
dat$x1[90:105]=NA
lm(dat$y ~ dat$x1 + dat$x2)
attach(dat)
dim(y)
dim(x1)
lm(y ~ x1 + x2, data=dat)
?lm
is.na(dat$y)
!is.na(dat$y)
?attach
summary(y)
summary(y)
lm(y~x1)
dim(y)
mean(y)
y
with(dat, y)
lm(y~x1)
lm(y~x1, data=dat)
glm(y~x1)
summary(y)
attach(dat)
y
x
x1
x2
detachAllData()
detachAllData()
detach(y, x1, x2, x3)
rm(y, x1, x2, x3)
attach(dat)
y
x1
x2
lm(y~x1)
attach(data)
attach(dat)
detach(dat)
x1
x2
attach(dat)
dat2 = data.frame(x1=1:10, x2=1:10, y=1:10)
dat2
attach(dat2)
x1
x2
y
attach(dat)
x1
x2
y
lm(y ~ x1 + x2)
RoundingTimes <-
matrix(c(5.40, 5.50, 5.55,
5.85, 5.70, 5.75,
5.20, 5.60, 5.50,
5.55, 5.50, 5.40,
5.90, 5.85, 5.70,
5.45, 5.55, 5.60,
5.40, 5.40, 5.35,
5.45, 5.50, 5.35,
5.25, 5.15, 5.00,
5.85, 5.80, 5.70,
5.25, 5.20, 5.10,
5.65, 5.55, 5.45,
5.60, 5.35, 5.45,
5.05, 5.00, 4.95,
5.50, 5.50, 5.40,
5.45, 5.55, 5.50,
5.55, 5.55, 5.35,
5.45, 5.50, 5.55,
5.50, 5.45, 5.25,
5.65, 5.60, 5.40,
5.70, 5.65, 5.55,
6.30, 6.30, 6.25),
nrow = 22,
byrow = TRUE,
dimnames = list(1 : 22,
c("Round Out", "Narrow Angle", "Wide Angle")))
View(RoundingTimes)
View(RoundingTimes)
View(RoundingTimes)
friedman.test(RoundingTimes)
wb <- aggregate(warpbreaks$breaks,
by = list(w = warpbreaks$wool,
t = warpbreaks$tension),
FUN = mean)
wb
friedman.test(wb$x, wb$w, wb$t)
friedman.test(x ~ w | t, data=wb)
rm(list=ls())
ls()
?strptime
library(lattice)
library(datasets)
xyplot(Ozone ~ Wind, data=airquality)
str(airquality)
xyplot(Ozone ~ Wind | as.factor(Month), data=airquality)
?transform
View(airquality)
transform(airquality, Ozone = -Ozone)
transform(airquality, new = -Ozone, Temp = (Temp-32)/1.8)
airquality = transform(airquality, Month=factor(Month))
xyplot(Ozone ~ Wind | Month, data=airquality, layout = c(5,1))
p = xyplot(Ozone ~ Wind, data=airquality)
print(p)
?panel
??panel
install.packages("ggplot2", dependencies = T)
library(ggplot2)
rm(ls())
rm(list=ls())
library(ggplot2)
str(mpg)
qplot(displ, hwy, data=mpg)
qplot(displ, hwy, data=mpg, color=drv)
qplot(displ, hwy, data=mpg, geom=c("point","smooth"))
str(maacs)
?qplot
qplot(displ, hwy, data=mpg, geom=c("point","smooth"), method="auto")
qplot(displ, hwy, data=mpg, geom=c("point","smooth"), method="loess")
?aes
?geom_point
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
BodyWeight$Diet
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
print(p)
library(ggplot2)
library(datasets)
data(airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
summary(airquality$Month)
summary(factor(airquality$Month))
str(airquality)
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
g + geom_point()
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, geom = c("point", "smooth"), methdo="lm")
qplot(votes, rating, data = movies, geom = c("point", "smooth"), method="lm")
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies) + stats_smooth("loess")
rep(1:3)
rep(1:3, each=4)
?rep
rep(1:3, times = 2)
rep(1:3, times = 2, each=2)
a = c(1, 0, 0, 1, 1, 1, 0, 1,0, 0, 0, 1, 1, 0, 1)
a
length(a)
a = c(1, 0, 0, 1, 1, 1, 0, 1,0, 0, 0, 1, 1, 0, 1, 1)
a
matrix(a, nrow = 4)
am = matrix(a, nrow = 4)
image(am)
?image
install.packages(c("ggplot2", "ggthemes", "PerformanceAnalytics", "psych",
"reshape2", "plyr", "RCurl", "devtools"))
install.packages(c("ggplot2", "ggthemes", "PerformanceAnalytics", "psych",
"reshape2", "plyr", "RCurl", "devtools"), dependencies = T)
install.packages(c("ggplot2", "ggthemes", "PerformanceAnalytics",
"psych",
+                    "reshape2", "plyr", "RCurl", "devtools"), dependencies = T)
install.packages(c("ggplot2", "ggthemes", "PerformanceAnalytics", "psych", "reshape2", "plyr", "RCurl", "devtools"), dependencies = T)
install.packages(c("ggplot2", "ggthemes", "PerformanceAnalytics",
"psych")
)
install.packages(c("ggplot2", "ggthemes", "PerformanceAnalytics",
)
)
install.packages(c("ggplot2", "ggthemes", "PerformanceAnalytics", "psych", "reshape2", "plyr", "RCurl", "devtools"))
install.packages(c("ggplot2", "ggthemes", "PerformanceAnalytics",
"RCurl")
)
install.packages(c("ggplot2", "ggthemes", "PerformanceAnalytics",
)
)
)
install.packages(c("ggplot2", "ggthemes", "PerformanceAnalytics"))
install.packages(c("ggplot2", "ggthemes", "PerformanceAnalytics"))
install.packages(c("ggplot2", "ggthemes", "PerformanceAnalytics"))
install.packages(c("ggplot2", "ggthemes", "PerformanceAnalytics"))
library(caret)
library(kernlab)
data(spam)
inTrain = createDataPartition(y=spam$type, p=0.75, list=FALSE)
training = spam[inTrain, ]
testing = spam[-inTrain, ]
dim(training)
dim(testing)
modelFit = train(type ~ ., data=training, method="glm")
modelFit
modelFit$finalModel
predictions = predict(modelFit, data=testing, method='glm')
predictions = predict(modelFit, newdata=testing)
predictions
predictions = predict(modelFit, newdata=testing, method='glm')
predictions = predict(modelFit, newdata=testing)
predictions = predict(modelFit, data=testing)
predictions = predict(modelFit, newdata=testing)
predictions
confusionMatrix(predictions, testing$type)
inTrain
str(inTrain)
folds = createFolds(y=spam$type, k=10, list=TRUE, returnTrain=T)
str(folds)
folds$Fold01
sapply(folds, length)
sapply(folds, sum)
sapply(folds, dim)
sapply(folds, length)
folds = createFolds(y=spam$type, k=10, list=TRUE, returnTrain=F)
sapply(folds, length)
folds = createResample(y=spam$type, times=10, list=TRUE)
sapply(folds, length)
folds = createTimeSlices(y=tme, initialWindow =11, horizon=10)
tme = 1:1000
folds = createTimeSlices(y=tme, initialWindow =11, horizon=10)
folds
folds = createTimeSlices(y=tme, initialWindow =11, horizon=100)
sapply(folds, length)
folds
names(folds)
str(folds)
install.packages("ISLR", dependencies = T)
library(ISLR)
library(ISLR)
library(ggplot2)
library(caret)
data(Wage)
summary(Wage)
inTrain = createDataPartition(y=Wage$wage, p=0.7, list=F)
training = Wage[inTrain, ]
testing = Wage[-inTrain, ]
dim(training);
dim(testing);
featurePlot(x=training[, c("age", "education", "jobclass")],
y=training$wage,
plot="pairs"
)
qplot(age, wage, data=training)
rm(airquality)
data(Wage)
summary(Wage)
inTrain = createDataPartition(y=Wage$wage, p=0.7, list=F)
head(inTrain, 20)
inTrain
str(inTrain)
str(wage)
str(Wage)
nsv = nearZeroVar(Wage, saveMetrics=T)
nsv
0.23685^2
0.44309^2
inTrain = createDataPartition(y=spam$type, p=0.75, list=FALSE)
training = spam[inTrain, ]
testing = spam[-inTrain, ]
abs(cor(training[,-58]))
abs(cor(training[,-58]))
which(M>0.8, arr.ind=T)
M = abs(cor(training[,-58]))
diag(M) = 0
which(M>0.8, arr.ind=T)
which(M>0.8)
names(spam)[c(32, 34)]
str(Wage)
modFit = train(wage ~ age+jobclass+education, method="lm", data=Wage)
finMod = modFit$finalModel
print(modFit)
summary(finMod)
plot(finMod, 1, pch=19, cex=0.5, col="#000")
plot(finMod, 1, pch=19, cex=0.5, col="#00000010")
install.packages("AppliedPredictiveModeling", dependencies=TRUE)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
View(predictors)
adData = data.frame(diagnosis,predictors)
View(adData)
str(diagnosis)
trainIndex = createDataPartition(diagnosis, p = 0.50)
str(trainIndex)
training = adData[trainIndex,]
trainIndex = createDataPartition(diagnosis, p = 0.50, list=F)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
View(training)
View(testing)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(mixtures$Superplasticizer)
str(hist)
?hist
hist(mixtures$Superplasticizer, breaks = 20)
hist(log(mixtures$Superplasticizer), breaks = 20)
summary(mixtures$Superplasticizer)
hist(log(mixtures$Superplasticizer + 1), breaks = 20)
hist(log(mixtures$Superplasticizer + 2), breaks = 20)
nearZeroVar(mixtures, saveMetrics=T)
hist(log(mixtures$Superplasticizer), breaks = 20)
summary(log(mixtures$Superplasticizer))
unique(mixtures$Superplasticizer)
sum(mixtures$Superplasticizer=0.0)
sum(mixtures$Superplasticizer==0.0)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(predictors)
grep(names(predictors),"IL")
?grep
grep
grep("IL", names(predictors))
ind = grep("IL", nms)
nms = names(predictors)
ind = grep("IL", nms)
nms[ind]
ind = grep("^IL", nms)
nms[ind]
ils = predictors[,ind]
head(ils)
?preProcess
preProcess(ils, method="pca", k=10)
pcas = preProcess(ils, method="pca", k=10)
summary(pcas)
pcas$k
pcas$ranges
pcas$pcaComp
pcas$method
pcas = preProcess(ils, method="pca", k=10, pcaComp=2)
str(pcas)
pcas = preProcess(ils, method="pca", thresh=0.95)
str(pcas)
pcas$numComp
pcas = preProcess(ils, method="pca", thresh=0.9)
pcas$numComp
pcas = preProcess(ils, method="pca", thresh=0.5)
pcas$numComp
pcas$numComp
pcas = preProcess(ils, method="pca", thresh=0.95)
pcas$numComp
pcas = preProcess(ils, method="pca", thresh=0.90)
pcas$numComp
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ils = predictors[,ind]
newd = data.frame(diagnosis, predictors)
View(newd)
nms = names(adData)
ind = grep("^IL", nms)
nms[ind]
c(1, ind)
newt = training[, c(1, ind)]
newte = testing[, c(1, ind)]
newtr = training[, c(1, ind)]
newte = testing[, c(1, ind)]
View(newtr)
View(newte)
trainControl( preProcOptions = list(thresh=0.80, method="pca"))
ctrl = trainControl( preProcOptions = list(thresh=0.80))
mod1 <- train(Class ~ .,data = newtr, method = "glm", preProcess="pca", trControl=ctrl)
mod2 <- train(Class ~ .,data = newtr, method = "glm")
mod1 <- train(diagnosis ~ .,data = newtr, method = "glm", preProcess="pca", trControl=ctrl)
mod2 <- train(diagnosis ~ .,data = newtr, method = "glm")
pred1 = predict(mod1, newdata=newte)
pred2 = predict(mod2, newdata=newte)
head(pred1)
table(pred1, newte$diagnosis)
table(pred2, newte$diagnosis)
table(pred1, newte$diagnosis)
table(pred2, newte$diagnosis)
t1 = table(pred1, newte$diagnosis)
t2 = table(pred2, newte$diagnosis)
t1
t1[1,1]
t1[1,2]
sum(t1)
diag(t1)
acc1 = sum(diag(t1))/sum(t1)
acc2 = sum(diag(t2))/sum(t2)
acc1
aacc1
aac2
acc2
print("accuracy is "m acc1)
print("accuracy is ", acc1)
print(paste("accuracy is ", acc1))
print(paste("accuracy with pca is    ", acc1))
print(paste("accuracy without pca is ", acc2))
print(paste("accuracy with pca is    ", round(acc1, digits=2)))
print(paste("accuracy with pca is    ", round(acc1, digits=2)))
print(paste("accuracy without pca is ", round(acc2, digits=2)))
script.dir <- dirname(sys.frame(1)$ofile)
source('~/GoogleDrive/Courses/DataScience_Coursera/PracticalMachineLearning/Wearable_Data_ML/machine_learning.R')
source('~/GoogleDrive/Courses/DataScience_Coursera/PracticalMachineLearning/Wearable_Data_ML/machine_learning.R')
postResample(pred$mod1, testing$classe)
confusionMatrix(pred$mod1, testing$classe)
Rpara = makePSOCKcluster(2) # can run 3 at the same time
registerDoParallel(Rpara);
ctrl = trainControl(method="cv", number=5, allowParallel=TRUE)
print(models[2])
allM$mod2 = train(classe ~ ., data=training, method=models[2], trControl=ctrl, prox=T)
allM$mod1
allM$mod2
